# Data prepation

This repository contains all the tools and code used to build the ROOTS dataset produced by the BigScience initiative to train the BLOOM models as well as a reduced version to train the tokenizer.

# [Code for making the Pseudo-Crawl dataset](https://github.com/bigscience-workshop/data-preparation/tree/main/sourcing/cc_pseudo_crawl)

# [Filtering library used to filter OSCAR](https://github.com/bigscience-workshop/data-preparation/tree/main/preprocessing/oscar_filtering)

# [Code used to run preprocessing pipeline on crowdsourced dataset](https://github.com/bigscience-workshop/data-preparation/tree/main/preprocessing/catalogue_cleaning)

# [Code used for the tokenizer](https://github.com/bigscience-workshop/data-preparation/tree/main/preprocessing/tokenizer)

# [Code used for making the analysis and plots for the paper](https://github.com/bigscience-workshop/data-preparation/tree/main/analysis)
