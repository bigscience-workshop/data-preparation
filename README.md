# Data prepation

This repository contains all the tools and code used to build the ROOTS dataset produced by the BigScience initiative to train the BLOOM models as well as a reduced version to train the tokenizer.

## [Code for making the Pseudo-Crawl dataset](sourcing/cc_pseudo_crawl)

## [Filtering library used to filter OSCAR](preprocessing/training/01b_oscar_cleaning_and_filtering)

## [Code used to run preprocessing pipeline on crowdsourced dataset](preprocessing/training)

## [Code used for the tokenizer](preprocessing/tokenizer)

## [Code used for making the analysis and plots for the paper](analysis)
